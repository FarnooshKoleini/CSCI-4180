{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD5X8GXVT7db",
        "outputId": "03970cd3-5bd0-4e37-ea16-ac435d19a339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spark in /usr/local/lib/python3.9/dist-packages (0.2.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.9/dist-packages (3.3.2)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.9/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ],
      "source": [
        "%pip install spark\n",
        "%pip install pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"example\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qdypXN5YI12",
        "outputId": "6c32f120-cf4c-404c-ad70-01fd3d98e253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+----------+\n",
            "|fatality_year|fatalities|\n",
            "+-------------+----------+\n",
            "|         2005|      1453|\n",
            "|         2011|      1335|\n",
            "|         2018|      1050|\n",
            "|         2021|       984|\n",
            "|         1999|       906|\n",
            "|         2020|       901|\n",
            "|         2008|       825|\n",
            "|         2017|       775|\n",
            "|         2019|       732|\n",
            "|         2007|       712|\n",
            "+-------------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+--------------+----------+\n",
            "|fatality_month|fatalities|\n",
            "+--------------+----------+\n",
            "|            07|      3381|\n",
            "|            08|      3248|\n",
            "|            06|      1955|\n",
            "|            04|      1697|\n",
            "|            05|      1634|\n",
            "+--------------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# DataFrames\n",
        "# Use the DataFrames in Apache Spark to calculate the following:\n",
        "# 1. Fatalities per month (12.5 pts): Calculate the fatalities per month. Show the top five months\n",
        "# with the most fatalities, in descending order.\n",
        "# 2. Fatalities per year (12.5 pts): Calculate the fatalities per year. Show the top ten years with\n",
        "# the most fatalities, in descending order.\n",
        "\n",
        "from pyspark.sql.functions import year, month, countDistinct\n",
        "\n",
        "fatalities_df = spark.read.format(\"csv\").option(\"header\", True).load(\"combined_StormEvents_fatalities.csv\")\n",
        "\n",
        "# Create new columns 'fatality_month' from 'FAT_YEARMONTH' column\n",
        "fatalities_df = fatalities_df.withColumn('fatality_month', fatalities_df['FAT_YEARMONTH'].substr(5, 2))\n",
        "\n",
        "# Perform aggregation by month and count the distinct fatality IDs\n",
        "fatalities_by_month = fatalities_df.groupby('fatality_month').agg(countDistinct('FATALITY_ID').alias('fatalities')).orderBy('fatalities', ascending=False).limit(5)\n",
        "\n",
        "# Create new columns 'fatality_year' \n",
        "fatalities_df = fatalities_df.withColumn('fatality_year', substring('FAT_YEARMONTH', 1, 4))\n",
        "\n",
        "# Perform aggregation by year and count the distinct fatality IDs\n",
        "fatalities_by_year = fatalities_df.groupby('fatality_year') \\\n",
        "                                   .agg(countDistinct('FATALITY_ID').alias('fatalities')) \\\n",
        "                                   .orderBy('fatalities', ascending=False)\n",
        "\n",
        "# Show the results\n",
        "fatalities_by_year.show(10)\n",
        "fatalities_by_month.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btWgePwdcmB_",
        "outputId": "494e871a-4090-4c43-e1b8-f3b1f8959ecd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------------+----------+\n",
            "|fatality_year|fatalities|\n",
            "+-------------+----------+\n",
            "|         2005|      1453|\n",
            "|         2011|      1335|\n",
            "|         2018|      1050|\n",
            "|         2021|       984|\n",
            "|         1999|       906|\n",
            "|         2020|       901|\n",
            "|         2008|       825|\n",
            "|         2017|       775|\n",
            "|         2019|       732|\n",
            "|         2007|       712|\n",
            "+-------------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+--------------+----------+\n",
            "|fatality_month|fatalities|\n",
            "+--------------+----------+\n",
            "|            07|      3381|\n",
            "|            08|      3248|\n",
            "|            06|      1955|\n",
            "|            04|      1697|\n",
            "|            05|      1634|\n",
            "+--------------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# SparkSQL\n",
        "# Use SparkSQL to calculate the following:\n",
        "# 1. Fatalities per month (12.5 pts): Calculate the fatalities per month. Show the top five months\n",
        "# with the most fatalities, in descending order.\n",
        "# 2. Fatalities per year (12.5 pts): Calculate the fatalities per year. Show the top ten years with\n",
        "# the most fatalities, in descending order.\n",
        "\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create SparkSession\n",
        "spark = SparkSession.builder.appName(\"fatalities_analysis\").getOrCreate()\n",
        "\n",
        "# Load fatalities data from CSV file\n",
        "fatalities_df = spark.read.format(\"csv\").option(\"header\", True).load(\"combined_StormEvents_fatalities.csv\")\n",
        "\n",
        "# Register DataFrame as temporary view\n",
        "fatalities_df.createOrReplaceTempView(\"fatalities\")\n",
        "\n",
        "# Perform SQL query to calculate fatalities by year\n",
        "fatalities_by_year = spark.sql(\"SELECT SUBSTR(FAT_YEARMONTH, 1, 4) as fatality_year, COUNT(DISTINCT FATALITY_ID) as fatalities \\\n",
        "                                FROM fatalities \\\n",
        "                                GROUP BY fatality_year \\\n",
        "                                ORDER BY fatalities DESC\")\n",
        "\n",
        "# Create a temporary view for SparkSQL queries\n",
        "fatalities_df.createOrReplaceTempView(\"fatalities\")\n",
        "\n",
        "# Perform the SQL query to calculate fatalities by month\n",
        "fatalities_by_month = spark.sql(\"SELECT SUBSTRING(FAT_YEARMONTH, 5, 2) AS fatality_month, COUNT(DISTINCT FATALITY_ID) AS fatalities FROM fatalities GROUP BY fatality_month ORDER BY fatalities DESC LIMIT 5\")\n",
        "\n",
        "# Show the result\n",
        "fatalities_by_year.show(10)\n",
        "fatalities_by_month.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "interpreter": {
      "hash": "3f397720aeab5d6ca451ef8f0ac36045b34cc58f655e162f506e23ec1d195a3e"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
